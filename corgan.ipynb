{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [100/938], D Loss: 0.6737, G Loss: 1.0781, C Loss: -0.5561\n",
      "FID: 646.3960\n",
      "Epoch [1/50], Step [200/938], D Loss: 0.5147, G Loss: 1.0884, C Loss: -0.4572\n",
      "FID: 629.6238\n",
      "Epoch [1/50], Step [300/938], D Loss: 1.1323, G Loss: 4.0433, C Loss: -0.8733\n",
      "FID: 539.4003\n",
      "Epoch [1/50], Step [400/938], D Loss: 0.0564, G Loss: 6.2846, C Loss: -0.0306\n",
      "FID: 1119.1566\n",
      "Epoch [1/50], Step [500/938], D Loss: 0.0132, G Loss: 5.4450, C Loss: -0.0070\n",
      "FID: 698.2001\n",
      "Epoch [1/50], Step [600/938], D Loss: 0.0215, G Loss: 5.4982, C Loss: -0.0120\n",
      "FID: 791.9681\n",
      "Epoch [1/50], Step [700/938], D Loss: 0.0258, G Loss: 5.8234, C Loss: -0.0194\n",
      "FID: 993.8335\n",
      "Epoch [1/50], Step [800/938], D Loss: 0.2090, G Loss: 6.5350, C Loss: -0.0619\n",
      "FID: 692.0970\n",
      "Epoch [1/50], Step [900/938], D Loss: 0.0247, G Loss: 6.9604, C Loss: -0.0044\n",
      "FID: 682.5984\n",
      "Epoch [2/50], Step [100/938], D Loss: 0.0333, G Loss: 6.9463, C Loss: -0.0164\n",
      "FID: 698.4067\n",
      "Epoch [2/50], Step [200/938], D Loss: 0.0316, G Loss: 6.8694, C Loss: -0.0169\n",
      "FID: 411.7568\n",
      "Epoch [2/50], Step [300/938], D Loss: 0.2342, G Loss: 10.3013, C Loss: -0.1634\n",
      "FID: 305.6897\n",
      "Epoch [2/50], Step [400/938], D Loss: 0.0194, G Loss: 7.3591, C Loss: -0.0126\n",
      "FID: 506.9623\n",
      "Epoch [2/50], Step [500/938], D Loss: 0.0554, G Loss: 7.1994, C Loss: -0.0234\n",
      "FID: 420.7051\n",
      "Epoch [2/50], Step [600/938], D Loss: 0.1624, G Loss: 5.9057, C Loss: -0.1001\n",
      "FID: 275.8060\n",
      "Epoch [2/50], Step [700/938], D Loss: 0.1883, G Loss: 5.2987, C Loss: -0.0344\n",
      "FID: 315.7596\n",
      "Epoch [2/50], Step [800/938], D Loss: 0.1190, G Loss: 5.8933, C Loss: -0.0994\n",
      "FID: 275.1891\n",
      "Epoch [2/50], Step [900/938], D Loss: 0.9837, G Loss: 3.9711, C Loss: -0.5057\n",
      "FID: 232.0602\n",
      "Epoch [3/50], Step [100/938], D Loss: 0.3413, G Loss: 7.7398, C Loss: -0.0338\n",
      "FID: 240.3372\n",
      "Epoch [3/50], Step [200/938], D Loss: 0.0514, G Loss: 6.4699, C Loss: -0.0327\n",
      "FID: 370.0410\n",
      "Epoch [3/50], Step [300/938], D Loss: 0.1629, G Loss: 5.7386, C Loss: -0.1219\n",
      "FID: 385.6048\n",
      "Epoch [3/50], Step [400/938], D Loss: 0.2001, G Loss: 4.6389, C Loss: -0.0578\n",
      "FID: 180.3243\n",
      "Epoch [3/50], Step [500/938], D Loss: 0.3822, G Loss: 4.5873, C Loss: -0.1520\n",
      "FID: 195.1470\n",
      "Epoch [3/50], Step [600/938], D Loss: 1.2869, G Loss: 2.8329, C Loss: -0.6781\n",
      "FID: 214.4673\n",
      "Epoch [3/50], Step [700/938], D Loss: 0.9798, G Loss: 3.2183, C Loss: -0.4352\n",
      "FID: 215.5433\n",
      "Epoch [3/50], Step [800/938], D Loss: 1.3273, G Loss: 2.2015, C Loss: -0.5071\n",
      "FID: 191.2740\n",
      "Epoch [3/50], Step [900/938], D Loss: 0.7127, G Loss: 2.8372, C Loss: -0.2592\n",
      "FID: 243.7759\n",
      "Epoch [4/50], Step [100/938], D Loss: 2.7081, G Loss: 1.0553, C Loss: -1.6967\n",
      "FID: 185.8241\n",
      "Epoch [4/50], Step [200/938], D Loss: 1.3631, G Loss: 2.0776, C Loss: -0.4849\n",
      "FID: 208.5085\n",
      "Epoch [4/50], Step [300/938], D Loss: 0.3605, G Loss: 4.6821, C Loss: -0.0708\n",
      "FID: 223.0359\n",
      "Epoch [4/50], Step [400/938], D Loss: 0.5683, G Loss: 5.9705, C Loss: -0.4302\n",
      "FID: 227.8608\n",
      "Epoch [4/50], Step [500/938], D Loss: 0.9958, G Loss: 2.0113, C Loss: -0.4210\n",
      "FID: 174.8599\n",
      "Epoch [4/50], Step [600/938], D Loss: 1.1135, G Loss: 1.2775, C Loss: -0.5069\n",
      "FID: 202.3557\n",
      "Epoch [4/50], Step [700/938], D Loss: 0.8274, G Loss: 1.9537, C Loss: -0.4144\n",
      "FID: 192.1275\n",
      "Epoch [4/50], Step [800/938], D Loss: 0.4813, G Loss: 5.0234, C Loss: -0.2598\n",
      "FID: 202.5036\n",
      "Epoch [4/50], Step [900/938], D Loss: 0.9444, G Loss: 1.3261, C Loss: -0.4992\n",
      "FID: 186.0990\n",
      "Epoch [5/50], Step [100/938], D Loss: 2.0621, G Loss: 0.9347, C Loss: -1.0335\n",
      "FID: 162.4975\n",
      "Epoch [5/50], Step [200/938], D Loss: 0.8962, G Loss: 2.2399, C Loss: -0.4167\n",
      "FID: 169.4378\n",
      "Epoch [5/50], Step [300/938], D Loss: 1.1989, G Loss: 1.4800, C Loss: -0.5479\n",
      "FID: 220.1631\n",
      "Epoch [5/50], Step [400/938], D Loss: 0.9844, G Loss: 2.3683, C Loss: -0.3190\n",
      "FID: 231.0392\n",
      "Epoch [5/50], Step [500/938], D Loss: 1.6072, G Loss: 2.7000, C Loss: -0.3316\n",
      "FID: 230.6132\n",
      "Epoch [5/50], Step [600/938], D Loss: 1.1372, G Loss: 1.5637, C Loss: -0.5254\n",
      "FID: 204.4636\n",
      "Epoch [5/50], Step [700/938], D Loss: 1.4508, G Loss: 1.1822, C Loss: -0.6377\n",
      "FID: 183.1890\n",
      "Epoch [5/50], Step [800/938], D Loss: 2.3855, G Loss: 1.0854, C Loss: -1.1994\n",
      "FID: 204.0146\n",
      "Epoch [5/50], Step [900/938], D Loss: 0.7171, G Loss: 2.1325, C Loss: -0.2799\n",
      "FID: 203.4957\n",
      "Epoch [6/50], Step [100/938], D Loss: 0.5135, G Loss: 2.2060, C Loss: -0.2587\n",
      "FID: 177.3508\n",
      "Epoch [6/50], Step [200/938], D Loss: 0.7888, G Loss: 2.3371, C Loss: -0.3090\n",
      "FID: 169.1652\n",
      "Epoch [6/50], Step [300/938], D Loss: 0.6224, G Loss: 2.0961, C Loss: -0.1951\n",
      "FID: 195.4959\n",
      "Epoch [6/50], Step [400/938], D Loss: 0.2124, G Loss: 2.7060, C Loss: -0.1143\n",
      "FID: 202.4101\n",
      "Epoch [6/50], Step [500/938], D Loss: 0.4200, G Loss: 3.2834, C Loss: -0.1858\n",
      "FID: 188.3714\n",
      "Epoch [6/50], Step [600/938], D Loss: 0.3440, G Loss: 3.1553, C Loss: -0.3139\n",
      "FID: 212.3792\n",
      "Epoch [6/50], Step [700/938], D Loss: 0.2786, G Loss: 3.9959, C Loss: -0.0571\n",
      "FID: 189.0582\n",
      "Epoch [6/50], Step [800/938], D Loss: 0.7914, G Loss: 3.2778, C Loss: -0.1618\n",
      "FID: 154.4108\n",
      "Epoch [6/50], Step [900/938], D Loss: 0.5553, G Loss: 3.4288, C Loss: -0.2469\n",
      "FID: 168.2426\n",
      "Epoch [7/50], Step [100/938], D Loss: 0.3524, G Loss: 4.5784, C Loss: -0.0634\n",
      "FID: 206.8418\n",
      "Epoch [7/50], Step [200/938], D Loss: 0.4486, G Loss: 3.3783, C Loss: -0.1844\n",
      "FID: 147.9982\n",
      "Epoch [7/50], Step [300/938], D Loss: 0.6459, G Loss: 2.9209, C Loss: -0.1610\n",
      "FID: 164.7091\n",
      "Epoch [7/50], Step [400/938], D Loss: 0.5001, G Loss: 2.1950, C Loss: -0.2691\n",
      "FID: 146.3431\n",
      "Epoch [7/50], Step [500/938], D Loss: 1.1430, G Loss: 2.2749, C Loss: -0.4394\n",
      "FID: 140.7308\n",
      "Epoch [7/50], Step [600/938], D Loss: 0.9183, G Loss: 2.6087, C Loss: -0.4101\n",
      "FID: 174.6414\n",
      "Epoch [7/50], Step [700/938], D Loss: 0.8769, G Loss: 2.7368, C Loss: -0.4904\n",
      "FID: 173.6916\n",
      "Epoch [7/50], Step [800/938], D Loss: 0.3142, G Loss: 3.0249, C Loss: -0.1966\n",
      "FID: 224.0748\n",
      "Epoch [7/50], Step [900/938], D Loss: 0.6772, G Loss: 3.0999, C Loss: -0.2829\n",
      "FID: 194.0645\n",
      "Epoch [8/50], Step [100/938], D Loss: 0.3255, G Loss: 3.1910, C Loss: -0.1318\n",
      "FID: 201.5185\n",
      "Epoch [8/50], Step [200/938], D Loss: 0.2486, G Loss: 3.0609, C Loss: -0.1108\n",
      "FID: 281.6873\n",
      "Epoch [8/50], Step [300/938], D Loss: 0.4654, G Loss: 3.2872, C Loss: -0.1232\n",
      "FID: 184.2064\n",
      "Epoch [8/50], Step [400/938], D Loss: 0.1262, G Loss: 3.1807, C Loss: -0.0745\n",
      "FID: 225.5454\n",
      "Epoch [8/50], Step [500/938], D Loss: 0.3104, G Loss: 6.3729, C Loss: -0.0122\n",
      "FID: 301.4706\n",
      "Epoch [8/50], Step [600/938], D Loss: 0.3593, G Loss: 5.5727, C Loss: -0.0778\n",
      "FID: 248.3757\n",
      "Epoch [8/50], Step [700/938], D Loss: 0.0470, G Loss: 7.7302, C Loss: -0.0221\n",
      "FID: 334.3946\n",
      "Epoch [8/50], Step [800/938], D Loss: 0.1531, G Loss: 7.3559, C Loss: -0.0511\n",
      "FID: 365.9505\n",
      "Epoch [8/50], Step [900/938], D Loss: 0.3284, G Loss: 5.3607, C Loss: -0.0813\n",
      "FID: 217.4786\n",
      "Epoch [9/50], Step [100/938], D Loss: 0.9756, G Loss: 4.1580, C Loss: -0.2986\n",
      "FID: 254.8757\n",
      "Epoch [9/50], Step [200/938], D Loss: 0.5982, G Loss: 3.3847, C Loss: -0.1171\n",
      "FID: 174.9160\n",
      "Epoch [9/50], Step [300/938], D Loss: 0.5809, G Loss: 4.3651, C Loss: -0.1399\n",
      "FID: 258.3232\n",
      "Epoch [9/50], Step [400/938], D Loss: 0.3387, G Loss: 4.6576, C Loss: -0.0504\n",
      "FID: 194.2094\n",
      "Epoch [9/50], Step [500/938], D Loss: 0.3779, G Loss: 4.4075, C Loss: -0.1001\n",
      "FID: 157.6017\n",
      "Epoch [9/50], Step [600/938], D Loss: 0.7548, G Loss: 5.1441, C Loss: -0.2053\n",
      "FID: 427.2880\n",
      "Epoch [9/50], Step [700/938], D Loss: 0.4882, G Loss: 3.4476, C Loss: -0.1168\n",
      "FID: 201.6556\n",
      "Epoch [9/50], Step [800/938], D Loss: 0.2506, G Loss: 4.2076, C Loss: -0.0749\n",
      "FID: 313.6793\n",
      "Epoch [9/50], Step [900/938], D Loss: 0.2338, G Loss: 3.8864, C Loss: -0.0985\n",
      "FID: 206.0720\n",
      "Epoch [10/50], Step [100/938], D Loss: 0.3337, G Loss: 6.8423, C Loss: -0.0255\n",
      "FID: 231.0639\n",
      "Epoch [10/50], Step [200/938], D Loss: 0.5250, G Loss: 3.6675, C Loss: -0.3528\n",
      "FID: 194.5305\n",
      "Epoch [10/50], Step [300/938], D Loss: 0.5496, G Loss: 5.1712, C Loss: -0.1680\n",
      "FID: 294.6861\n",
      "Epoch [10/50], Step [400/938], D Loss: 0.1422, G Loss: 3.8481, C Loss: -0.0609\n",
      "FID: 392.2921\n",
      "Epoch [10/50], Step [500/938], D Loss: 0.0826, G Loss: 4.0130, C Loss: -0.0427\n",
      "FID: 292.9854\n",
      "Epoch [10/50], Step [600/938], D Loss: 0.0785, G Loss: 5.0352, C Loss: -0.0189\n",
      "FID: 388.0771\n",
      "Epoch [10/50], Step [700/938], D Loss: 0.1563, G Loss: 5.7284, C Loss: -0.1364\n",
      "FID: 593.4412\n",
      "Epoch [10/50], Step [800/938], D Loss: 0.2831, G Loss: 4.5946, C Loss: -0.0539\n",
      "FID: 481.1741\n",
      "Epoch [10/50], Step [900/938], D Loss: 0.4200, G Loss: 6.9246, C Loss: -0.2477\n",
      "FID: 305.0917\n",
      "Epoch [11/50], Step [100/938], D Loss: 0.2634, G Loss: 7.4253, C Loss: -0.0325\n",
      "FID: 327.4800\n",
      "Epoch [11/50], Step [200/938], D Loss: 0.1174, G Loss: 8.5508, C Loss: -0.0081\n",
      "FID: 482.3072\n",
      "Epoch [11/50], Step [300/938], D Loss: 0.4955, G Loss: 4.1686, C Loss: -0.2336\n",
      "FID: 245.6499\n",
      "Epoch [11/50], Step [400/938], D Loss: 0.1657, G Loss: 4.0992, C Loss: -0.1126\n",
      "FID: 290.2936\n",
      "Epoch [11/50], Step [500/938], D Loss: 0.1869, G Loss: 3.7898, C Loss: -0.1087\n",
      "FID: 256.5504\n",
      "Epoch [11/50], Step [600/938], D Loss: 0.4036, G Loss: 3.5948, C Loss: -0.1496\n",
      "FID: 213.9725\n",
      "Epoch [11/50], Step [700/938], D Loss: 0.1060, G Loss: 6.3773, C Loss: -0.0457\n",
      "FID: 254.9363\n",
      "Epoch [11/50], Step [800/938], D Loss: 0.3081, G Loss: 3.8816, C Loss: -0.0685\n",
      "FID: 178.1792\n",
      "Epoch [11/50], Step [900/938], D Loss: 0.2363, G Loss: 3.8667, C Loss: -0.0875\n",
      "FID: 221.2042\n",
      "Epoch [12/50], Step [100/938], D Loss: 0.1893, G Loss: 4.3483, C Loss: -0.0839\n",
      "FID: 185.1477\n",
      "Epoch [12/50], Step [200/938], D Loss: 0.3823, G Loss: 4.0628, C Loss: -0.1865\n",
      "FID: 217.4755\n",
      "Epoch [12/50], Step [300/938], D Loss: 3.6615, G Loss: 16.5195, C Loss: -1.0339\n",
      "FID: 313.5037\n",
      "Epoch [12/50], Step [400/938], D Loss: 0.2831, G Loss: 3.4652, C Loss: -0.1246\n",
      "FID: 314.0390\n",
      "Epoch [12/50], Step [500/938], D Loss: 0.0593, G Loss: 4.6144, C Loss: -0.0573\n",
      "FID: 542.3900\n",
      "Epoch [12/50], Step [600/938], D Loss: 0.2763, G Loss: 4.6356, C Loss: -0.0973\n",
      "FID: 356.4810\n",
      "Epoch [12/50], Step [700/938], D Loss: 0.4910, G Loss: 3.3900, C Loss: -0.1311\n",
      "FID: 257.5717\n",
      "Epoch [12/50], Step [800/938], D Loss: 0.1442, G Loss: 5.4735, C Loss: -0.0341\n",
      "FID: 269.6541\n",
      "Epoch [12/50], Step [900/938], D Loss: 0.0869, G Loss: 6.4094, C Loss: -0.0135\n",
      "FID: 384.9653\n",
      "Epoch [13/50], Step [100/938], D Loss: 0.3720, G Loss: 6.5946, C Loss: -0.0206\n",
      "FID: 392.3875\n",
      "Epoch [13/50], Step [200/938], D Loss: 0.4967, G Loss: 4.9175, C Loss: -0.0864\n",
      "FID: 267.3381\n",
      "Epoch [13/50], Step [300/938], D Loss: 0.2415, G Loss: 6.5343, C Loss: -0.0412\n",
      "FID: 416.8406\n",
      "Epoch [13/50], Step [400/938], D Loss: 0.1998, G Loss: 7.9361, C Loss: -0.0799\n",
      "FID: 334.9623\n",
      "Epoch [13/50], Step [500/938], D Loss: 0.5552, G Loss: 6.7495, C Loss: -0.0297\n",
      "FID: 268.1861\n",
      "Epoch [13/50], Step [600/938], D Loss: 0.2472, G Loss: 7.8791, C Loss: -0.0161\n",
      "FID: 326.3052\n",
      "Epoch [13/50], Step [700/938], D Loss: 0.1295, G Loss: 8.7231, C Loss: -0.0038\n",
      "FID: 303.2141\n",
      "Epoch [13/50], Step [800/938], D Loss: 0.1502, G Loss: 7.9138, C Loss: -0.0148\n",
      "FID: 659.2774\n",
      "Epoch [13/50], Step [900/938], D Loss: 0.1083, G Loss: 6.1907, C Loss: -0.0480\n",
      "FID: 333.4367\n",
      "Epoch [14/50], Step [100/938], D Loss: 0.0079, G Loss: 6.8277, C Loss: -0.0028\n",
      "FID: 439.2728\n",
      "Epoch [14/50], Step [200/938], D Loss: 0.0032, G Loss: 10.7560, C Loss: -0.0000\n",
      "FID: 576.3845\n",
      "Epoch [14/50], Step [300/938], D Loss: 0.0001, G Loss: 9.8961, C Loss: -0.0001\n",
      "FID: 695.3565\n",
      "Epoch [14/50], Step [400/938], D Loss: 0.0050, G Loss: 5.9780, C Loss: -0.0033\n",
      "FID: 701.6603\n",
      "Epoch [14/50], Step [500/938], D Loss: 0.0480, G Loss: 9.6258, C Loss: -0.0609\n",
      "FID: 456.8301\n",
      "Epoch [14/50], Step [600/938], D Loss: 0.1273, G Loss: 7.9454, C Loss: -0.0104\n",
      "FID: 381.7370\n",
      "Epoch [14/50], Step [700/938], D Loss: 0.2170, G Loss: 7.4452, C Loss: -0.0089\n",
      "FID: 473.5127\n",
      "Epoch [14/50], Step [800/938], D Loss: 0.0032, G Loss: 8.6692, C Loss: -0.0008\n",
      "FID: 669.2527\n",
      "Epoch [14/50], Step [900/938], D Loss: 0.0052, G Loss: 10.6896, C Loss: -0.0017\n",
      "FID: 438.7973\n",
      "Epoch [15/50], Step [100/938], D Loss: 0.0252, G Loss: 7.6210, C Loss: -0.0059\n",
      "FID: 365.2784\n",
      "Epoch [15/50], Step [200/938], D Loss: 0.1231, G Loss: 8.1824, C Loss: -0.0035\n",
      "FID: 298.9792\n",
      "Epoch [15/50], Step [300/938], D Loss: 0.0522, G Loss: 13.2816, C Loss: -0.0042\n",
      "FID: 439.0295\n",
      "Epoch [15/50], Step [400/938], D Loss: 0.1760, G Loss: 4.4369, C Loss: -0.2984\n",
      "FID: 267.6121\n",
      "Epoch [15/50], Step [500/938], D Loss: 0.1853, G Loss: 6.3060, C Loss: -0.1071\n",
      "FID: 328.0261\n",
      "Epoch [15/50], Step [600/938], D Loss: 0.1434, G Loss: 9.8548, C Loss: -0.2493\n",
      "FID: 354.9884\n",
      "Epoch [15/50], Step [700/938], D Loss: 0.1702, G Loss: 8.9241, C Loss: -0.0172\n",
      "FID: 302.8139\n",
      "Epoch [15/50], Step [800/938], D Loss: 0.0894, G Loss: 5.7687, C Loss: -0.0358\n",
      "FID: 388.8367\n",
      "Epoch [15/50], Step [900/938], D Loss: 0.4028, G Loss: 5.9839, C Loss: -0.0397\n",
      "FID: 234.1867\n",
      "Epoch [16/50], Step [100/938], D Loss: 0.1680, G Loss: 4.4404, C Loss: -0.0699\n",
      "FID: 302.6958\n",
      "Epoch [16/50], Step [200/938], D Loss: 0.5026, G Loss: 6.2036, C Loss: -0.3818\n",
      "FID: 344.4472\n",
      "Epoch [16/50], Step [300/938], D Loss: 0.5482, G Loss: 6.7873, C Loss: -0.1295\n",
      "FID: 235.1231\n",
      "Epoch [16/50], Step [400/938], D Loss: 0.2319, G Loss: 6.0533, C Loss: -0.0927\n",
      "FID: 432.4507\n",
      "Epoch [16/50], Step [500/938], D Loss: 0.4037, G Loss: 5.8188, C Loss: -0.2215\n",
      "FID: 240.5431\n",
      "Epoch [16/50], Step [600/938], D Loss: 0.0516, G Loss: 7.0982, C Loss: -0.0131\n",
      "FID: 384.4087\n",
      "Epoch [16/50], Step [700/938], D Loss: 0.5583, G Loss: 7.9820, C Loss: -0.2562\n",
      "FID: 411.9522\n",
      "Epoch [16/50], Step [800/938], D Loss: 0.1365, G Loss: 6.1150, C Loss: -0.0190\n",
      "FID: 291.6249\n",
      "Epoch [16/50], Step [900/938], D Loss: 0.2277, G Loss: 6.8660, C Loss: -0.0383\n",
      "FID: 308.3531\n",
      "Epoch [17/50], Step [100/938], D Loss: 0.2550, G Loss: 5.0268, C Loss: -0.0629\n",
      "FID: 280.6104\n",
      "Epoch [17/50], Step [200/938], D Loss: 0.3988, G Loss: 5.2067, C Loss: -0.1338\n",
      "FID: 173.4194\n",
      "Epoch [17/50], Step [300/938], D Loss: 0.1943, G Loss: 5.5568, C Loss: -0.0318\n",
      "FID: 289.7268\n",
      "Epoch [17/50], Step [400/938], D Loss: 0.1132, G Loss: 6.6340, C Loss: -0.0591\n",
      "FID: 321.9193\n",
      "Epoch [17/50], Step [500/938], D Loss: 0.3253, G Loss: 8.7144, C Loss: -0.0971\n",
      "FID: 352.4241\n",
      "Epoch [17/50], Step [600/938], D Loss: 0.1512, G Loss: 5.4492, C Loss: -0.0276\n",
      "FID: 258.7878\n",
      "Epoch [17/50], Step [700/938], D Loss: 0.2920, G Loss: 5.7999, C Loss: -0.0479\n",
      "FID: 317.2901\n",
      "Epoch [17/50], Step [800/938], D Loss: 0.1811, G Loss: 6.2173, C Loss: -0.1083\n",
      "FID: 364.9894\n",
      "Epoch [17/50], Step [900/938], D Loss: 0.1727, G Loss: 4.6407, C Loss: -0.0770\n",
      "FID: 178.4239\n",
      "Epoch [18/50], Step [100/938], D Loss: 0.2858, G Loss: 3.9663, C Loss: -0.1896\n",
      "FID: 208.8167\n",
      "Epoch [18/50], Step [200/938], D Loss: 0.0687, G Loss: 5.7053, C Loss: -0.0345\n",
      "FID: 215.8537\n",
      "Epoch [18/50], Step [300/938], D Loss: 0.2274, G Loss: 5.1949, C Loss: -0.0827\n",
      "FID: 175.4805\n",
      "Epoch [18/50], Step [400/938], D Loss: 0.1666, G Loss: 5.1206, C Loss: -0.0879\n",
      "FID: 272.2928\n",
      "Epoch [18/50], Step [500/938], D Loss: 0.5424, G Loss: 5.9118, C Loss: -0.0769\n",
      "FID: 259.1798\n",
      "Epoch [18/50], Step [600/938], D Loss: 0.2551, G Loss: 4.7109, C Loss: -0.2169\n",
      "FID: 200.3340\n",
      "Epoch [18/50], Step [700/938], D Loss: 0.0976, G Loss: 4.8352, C Loss: -0.0693\n",
      "FID: 256.6050\n",
      "Epoch [18/50], Step [800/938], D Loss: 0.3843, G Loss: 5.9123, C Loss: -0.0914\n",
      "FID: 305.6987\n",
      "Epoch [18/50], Step [900/938], D Loss: 0.1527, G Loss: 8.0778, C Loss: -0.1187\n",
      "FID: 289.0041\n",
      "Epoch [19/50], Step [100/938], D Loss: 0.2369, G Loss: 3.8713, C Loss: -0.2605\n",
      "FID: 211.1350\n",
      "Epoch [19/50], Step [200/938], D Loss: 0.2534, G Loss: 7.5803, C Loss: -0.0701\n",
      "FID: 163.8461\n",
      "Epoch [19/50], Step [300/938], D Loss: 0.2465, G Loss: 5.2412, C Loss: -0.1009\n",
      "FID: 136.9516\n",
      "Epoch [19/50], Step [400/938], D Loss: 0.3005, G Loss: 3.9963, C Loss: -0.1772\n",
      "FID: 148.8054\n",
      "Epoch [19/50], Step [500/938], D Loss: 0.2098, G Loss: 3.6225, C Loss: -0.1588\n",
      "FID: 115.2215\n",
      "Epoch [19/50], Step [600/938], D Loss: 0.5715, G Loss: 4.7752, C Loss: -0.3241\n",
      "FID: 148.8142\n",
      "Epoch [19/50], Step [700/938], D Loss: 0.2934, G Loss: 3.3976, C Loss: -0.2278\n",
      "FID: 110.5913\n",
      "Epoch [19/50], Step [800/938], D Loss: 0.2714, G Loss: 3.6727, C Loss: -0.1760\n",
      "FID: 107.1697\n",
      "Epoch [19/50], Step [900/938], D Loss: 0.1443, G Loss: 4.0869, C Loss: -0.0916\n",
      "FID: 114.9214\n",
      "Epoch [20/50], Step [100/938], D Loss: 0.2680, G Loss: 3.0138, C Loss: -0.2493\n",
      "FID: 142.3652\n",
      "Epoch [20/50], Step [200/938], D Loss: 0.3410, G Loss: 3.4891, C Loss: -0.1723\n",
      "FID: 94.6168\n",
      "Epoch [20/50], Step [300/938], D Loss: 0.5414, G Loss: 3.0461, C Loss: -0.2228\n",
      "FID: 101.0278\n",
      "Epoch [20/50], Step [400/938], D Loss: 0.1929, G Loss: 3.5427, C Loss: -0.1303\n",
      "FID: 98.6105\n",
      "Epoch [20/50], Step [500/938], D Loss: 0.3307, G Loss: 3.4728, C Loss: -0.2854\n",
      "FID: 107.4050\n",
      "Epoch [20/50], Step [600/938], D Loss: 0.3144, G Loss: 2.9070, C Loss: -0.2066\n",
      "FID: 97.4527\n",
      "Epoch [20/50], Step [700/938], D Loss: 0.4706, G Loss: 3.0202, C Loss: -0.2743\n",
      "FID: 89.1324\n",
      "Epoch [20/50], Step [800/938], D Loss: 0.6635, G Loss: 2.8787, C Loss: -0.4457\n",
      "FID: 69.1889\n",
      "Epoch [20/50], Step [900/938], D Loss: 0.3430, G Loss: 3.9183, C Loss: -0.0912\n",
      "FID: 95.0560\n",
      "Epoch [21/50], Step [100/938], D Loss: 0.7868, G Loss: 4.0387, C Loss: -0.0949\n",
      "FID: 83.5087\n",
      "Epoch [21/50], Step [200/938], D Loss: 0.3630, G Loss: 3.8439, C Loss: -0.0867\n",
      "FID: 88.6086\n",
      "Epoch [21/50], Step [300/938], D Loss: 0.3423, G Loss: 4.4046, C Loss: -0.0555\n",
      "FID: 93.2623\n",
      "Epoch [21/50], Step [400/938], D Loss: 0.4656, G Loss: 3.1575, C Loss: -0.1402\n",
      "FID: 107.9341\n",
      "Epoch [21/50], Step [500/938], D Loss: 0.6479, G Loss: 2.8237, C Loss: -0.2795\n",
      "FID: 92.4965\n",
      "Epoch [21/50], Step [600/938], D Loss: 0.5279, G Loss: 3.2765, C Loss: -0.1308\n",
      "FID: 77.7642\n",
      "Epoch [21/50], Step [700/938], D Loss: 0.4413, G Loss: 3.1759, C Loss: -0.1102\n",
      "FID: 61.3457\n",
      "Epoch [21/50], Step [800/938], D Loss: 0.4687, G Loss: 3.1522, C Loss: -0.1139\n",
      "FID: 77.4399\n",
      "Epoch [21/50], Step [900/938], D Loss: 0.5342, G Loss: 2.6863, C Loss: -0.1784\n",
      "FID: 69.6736\n",
      "Epoch [22/50], Step [100/938], D Loss: 0.5413, G Loss: 3.7057, C Loss: -0.1412\n",
      "FID: 107.7426\n",
      "Epoch [22/50], Step [200/938], D Loss: 0.3245, G Loss: 4.8459, C Loss: -0.0311\n",
      "FID: 76.3432\n",
      "Epoch [22/50], Step [300/938], D Loss: 0.3818, G Loss: 3.4339, C Loss: -0.0881\n",
      "FID: 86.2163\n",
      "Epoch [22/50], Step [400/938], D Loss: 0.4941, G Loss: 4.2490, C Loss: -0.0733\n",
      "FID: 77.7544\n",
      "Epoch [22/50], Step [500/938], D Loss: 0.5300, G Loss: 3.9970, C Loss: -0.1347\n",
      "FID: 106.2274\n",
      "Epoch [22/50], Step [600/938], D Loss: 0.4166, G Loss: 4.4450, C Loss: -0.0763\n",
      "FID: 138.6980\n",
      "Epoch [22/50], Step [700/938], D Loss: 0.3977, G Loss: 3.3449, C Loss: -0.0980\n",
      "FID: 90.0257\n",
      "Epoch [22/50], Step [800/938], D Loss: 0.4560, G Loss: 2.9033, C Loss: -0.1817\n",
      "FID: 67.2574\n",
      "Epoch [22/50], Step [900/938], D Loss: 0.5842, G Loss: 2.6394, C Loss: -0.2641\n",
      "FID: 77.8892\n",
      "Epoch [23/50], Step [100/938], D Loss: 0.6352, G Loss: 3.5257, C Loss: -0.1787\n",
      "FID: 82.6485\n",
      "Epoch [23/50], Step [200/938], D Loss: 0.5536, G Loss: 2.3551, C Loss: -0.3388\n",
      "FID: 72.7398\n",
      "Epoch [23/50], Step [300/938], D Loss: 0.6191, G Loss: 2.5458, C Loss: -0.4119\n",
      "FID: 98.9986\n",
      "Epoch [23/50], Step [400/938], D Loss: 0.5320, G Loss: 3.4731, C Loss: -0.1429\n",
      "FID: 87.0353\n",
      "Epoch [23/50], Step [500/938], D Loss: 0.3923, G Loss: 3.4019, C Loss: -0.1593\n",
      "FID: 96.2030\n",
      "Epoch [23/50], Step [600/938], D Loss: 0.3486, G Loss: 3.0923, C Loss: -0.1688\n",
      "FID: 106.8651\n",
      "Epoch [23/50], Step [700/938], D Loss: 0.3281, G Loss: 2.9339, C Loss: -0.1442\n",
      "FID: 75.4421\n",
      "Epoch [23/50], Step [800/938], D Loss: 0.4587, G Loss: 2.9384, C Loss: -0.1714\n",
      "FID: 70.4343\n",
      "Epoch [23/50], Step [900/938], D Loss: 0.5488, G Loss: 3.5527, C Loss: -0.1390\n",
      "FID: 69.4812\n",
      "Epoch [24/50], Step [100/938], D Loss: 0.8642, G Loss: 2.7480, C Loss: -0.3646\n",
      "FID: 87.2947\n",
      "Epoch [24/50], Step [200/938], D Loss: 0.6022, G Loss: 3.0607, C Loss: -0.2492\n",
      "FID: 78.2513\n",
      "Epoch [24/50], Step [300/938], D Loss: 0.3341, G Loss: 4.1722, C Loss: -0.0717\n",
      "FID: 89.8540\n",
      "Epoch [24/50], Step [400/938], D Loss: 0.5216, G Loss: 2.9694, C Loss: -0.1996\n",
      "FID: 108.9586\n",
      "Epoch [24/50], Step [500/938], D Loss: 0.4554, G Loss: 3.3781, C Loss: -0.1679\n",
      "FID: 98.5972\n",
      "Epoch [24/50], Step [600/938], D Loss: 0.4577, G Loss: 3.4510, C Loss: -0.2991\n",
      "FID: 91.8618\n",
      "Epoch [24/50], Step [700/938], D Loss: 0.3431, G Loss: 4.8454, C Loss: -0.0463\n",
      "FID: 86.2189\n",
      "Epoch [24/50], Step [800/938], D Loss: 0.5222, G Loss: 4.6105, C Loss: -0.0847\n",
      "FID: 116.9244\n",
      "Epoch [24/50], Step [900/938], D Loss: 0.4141, G Loss: 3.5352, C Loss: -0.1672\n",
      "FID: 107.3572\n",
      "Epoch [25/50], Step [100/938], D Loss: 0.3512, G Loss: 3.6970, C Loss: -0.1569\n",
      "FID: 121.3222\n",
      "Epoch [25/50], Step [200/938], D Loss: 0.5139, G Loss: 3.1182, C Loss: -0.1395\n",
      "FID: 67.5228\n",
      "Epoch [25/50], Step [300/938], D Loss: 0.2802, G Loss: 3.9311, C Loss: -0.1321\n",
      "FID: 147.1381\n",
      "Epoch [25/50], Step [400/938], D Loss: 0.1611, G Loss: 5.0100, C Loss: -0.0450\n",
      "FID: 119.7030\n",
      "Epoch [25/50], Step [500/938], D Loss: 0.2451, G Loss: 4.5983, C Loss: -0.0533\n",
      "FID: 105.3588\n",
      "Epoch [25/50], Step [600/938], D Loss: 0.6571, G Loss: 2.3187, C Loss: -0.3226\n",
      "FID: 99.8967\n",
      "Epoch [25/50], Step [700/938], D Loss: 0.5001, G Loss: 3.6697, C Loss: -0.1483\n",
      "FID: 77.8248\n",
      "Epoch [25/50], Step [800/938], D Loss: 0.5191, G Loss: 3.1360, C Loss: -0.1481\n",
      "FID: 71.1254\n",
      "Epoch [25/50], Step [900/938], D Loss: 0.3621, G Loss: 3.4389, C Loss: -0.0879\n",
      "FID: 73.9784\n",
      "Epoch [26/50], Step [100/938], D Loss: 0.3604, G Loss: 2.5981, C Loss: -0.1766\n",
      "FID: 68.1248\n",
      "Epoch [26/50], Step [200/938], D Loss: 0.4750, G Loss: 3.8095, C Loss: -0.1730\n",
      "FID: 148.6069\n",
      "Epoch [26/50], Step [300/938], D Loss: 0.3857, G Loss: 3.0715, C Loss: -0.3543\n",
      "FID: 134.9586\n",
      "Epoch [26/50], Step [400/938], D Loss: 0.6865, G Loss: 2.3014, C Loss: -0.4488\n",
      "FID: 81.9413\n",
      "Epoch [26/50], Step [500/938], D Loss: 0.4570, G Loss: 3.6154, C Loss: -0.1224\n",
      "FID: 81.4672\n",
      "Epoch [26/50], Step [600/938], D Loss: 0.5794, G Loss: 2.9787, C Loss: -0.3222\n",
      "FID: 84.6112\n",
      "Epoch [26/50], Step [700/938], D Loss: 0.4308, G Loss: 3.0727, C Loss: -0.1520\n",
      "FID: 82.7695\n",
      "Epoch [26/50], Step [800/938], D Loss: 0.5158, G Loss: 2.7514, C Loss: -0.1985\n",
      "FID: 56.7347\n",
      "Epoch [26/50], Step [900/938], D Loss: 0.4355, G Loss: 3.7758, C Loss: -0.0889\n",
      "FID: 67.6425\n",
      "Epoch [27/50], Step [100/938], D Loss: 0.5763, G Loss: 2.4695, C Loss: -0.2889\n",
      "FID: 64.4101\n",
      "Epoch [27/50], Step [200/938], D Loss: 0.4517, G Loss: 3.0045, C Loss: -0.1792\n",
      "FID: 58.6139\n",
      "Epoch [27/50], Step [300/938], D Loss: 0.6445, G Loss: 2.9330, C Loss: -0.2151\n",
      "FID: 67.1280\n",
      "Epoch [27/50], Step [400/938], D Loss: 0.4804, G Loss: 2.8253, C Loss: -0.2280\n",
      "FID: 99.0746\n",
      "Epoch [27/50], Step [500/938], D Loss: 0.4334, G Loss: 2.6481, C Loss: -0.2129\n",
      "FID: 67.5048\n",
      "Epoch [27/50], Step [600/938], D Loss: 0.2288, G Loss: 4.0889, C Loss: -0.0650\n",
      "FID: 79.0551\n",
      "Epoch [27/50], Step [700/938], D Loss: 0.3275, G Loss: 3.6606, C Loss: -0.0758\n",
      "FID: 77.1259\n",
      "Epoch [27/50], Step [800/938], D Loss: 0.4357, G Loss: 4.1006, C Loss: -0.0943\n",
      "FID: 83.3933\n",
      "Epoch [27/50], Step [900/938], D Loss: 0.6503, G Loss: 2.0474, C Loss: -0.4797\n",
      "FID: 50.9509\n",
      "Epoch [28/50], Step [100/938], D Loss: 0.8390, G Loss: 3.6305, C Loss: -0.1084\n",
      "FID: 64.5573\n",
      "Epoch [28/50], Step [200/938], D Loss: 0.5580, G Loss: 3.6044, C Loss: -0.1320\n",
      "FID: 69.1862\n",
      "Epoch [28/50], Step [300/938], D Loss: 0.4308, G Loss: 2.7458, C Loss: -0.1532\n",
      "FID: 86.4882\n",
      "Epoch [28/50], Step [400/938], D Loss: 0.5596, G Loss: 2.1604, C Loss: -0.3702\n",
      "FID: 51.0650\n",
      "Epoch [28/50], Step [500/938], D Loss: 0.2982, G Loss: 2.1815, C Loss: -0.3647\n",
      "FID: 65.6354\n",
      "Epoch [28/50], Step [600/938], D Loss: 0.5171, G Loss: 2.6444, C Loss: -0.2902\n",
      "FID: 62.9829\n",
      "Epoch [28/50], Step [700/938], D Loss: 0.4912, G Loss: 3.2102, C Loss: -0.1444\n",
      "FID: 80.4373\n",
      "Epoch [28/50], Step [800/938], D Loss: 0.7563, G Loss: 3.0343, C Loss: -0.2310\n",
      "FID: 76.4528\n",
      "Epoch [28/50], Step [900/938], D Loss: 0.4073, G Loss: 2.9913, C Loss: -0.1942\n",
      "FID: 71.0498\n",
      "Epoch [29/50], Step [100/938], D Loss: 0.6434, G Loss: 2.5394, C Loss: -0.3505\n",
      "FID: 92.1222\n",
      "Epoch [29/50], Step [200/938], D Loss: 0.5223, G Loss: 2.1470, C Loss: -0.3470\n",
      "FID: 66.7414\n",
      "Epoch [29/50], Step [300/938], D Loss: 0.6920, G Loss: 2.9704, C Loss: -0.1374\n",
      "FID: 52.9305\n",
      "Epoch [29/50], Step [400/938], D Loss: 0.5213, G Loss: 2.6057, C Loss: -0.2883\n",
      "FID: 63.1311\n",
      "Epoch [29/50], Step [500/938], D Loss: 0.6161, G Loss: 2.2652, C Loss: -0.3456\n",
      "FID: 83.8380\n",
      "Epoch [29/50], Step [600/938], D Loss: 0.5409, G Loss: 3.0668, C Loss: -0.1691\n",
      "FID: 80.8515\n",
      "Epoch [29/50], Step [700/938], D Loss: 0.4350, G Loss: 2.9351, C Loss: -0.1852\n",
      "FID: 60.3798\n",
      "Epoch [29/50], Step [800/938], D Loss: 0.6904, G Loss: 2.6140, C Loss: -0.2648\n",
      "FID: 56.9412\n",
      "Epoch [29/50], Step [900/938], D Loss: 0.4786, G Loss: 3.2029, C Loss: -0.1947\n",
      "FID: 70.8591\n",
      "Epoch [30/50], Step [100/938], D Loss: 0.6296, G Loss: 2.1919, C Loss: -0.3682\n",
      "FID: 67.1207\n",
      "Epoch [30/50], Step [200/938], D Loss: 0.5154, G Loss: 1.6873, C Loss: -0.3885\n",
      "FID: 75.6086\n",
      "Epoch [30/50], Step [300/938], D Loss: 0.6379, G Loss: 2.5228, C Loss: -0.2732\n",
      "FID: 66.9241\n",
      "Epoch [30/50], Step [400/938], D Loss: 0.5117, G Loss: 2.3688, C Loss: -0.2991\n",
      "FID: 54.8380\n",
      "Epoch [30/50], Step [500/938], D Loss: 0.6892, G Loss: 2.8127, C Loss: -0.2710\n",
      "FID: 71.2109\n",
      "Epoch [30/50], Step [600/938], D Loss: 0.5829, G Loss: 2.4002, C Loss: -0.3001\n",
      "FID: 66.4972\n",
      "Epoch [30/50], Step [700/938], D Loss: 0.8562, G Loss: 2.7574, C Loss: -0.2786\n",
      "FID: 68.5522\n",
      "Epoch [30/50], Step [800/938], D Loss: 0.6940, G Loss: 1.9701, C Loss: -0.5235\n",
      "FID: 76.0840\n",
      "Epoch [30/50], Step [900/938], D Loss: 0.6757, G Loss: 2.8536, C Loss: -0.2978\n",
      "FID: 79.1009\n",
      "Epoch [31/50], Step [100/938], D Loss: 0.9094, G Loss: 2.0204, C Loss: -0.4838\n",
      "FID: 59.5117\n",
      "Epoch [31/50], Step [200/938], D Loss: 0.6525, G Loss: 2.6114, C Loss: -0.2813\n",
      "FID: 70.2949\n",
      "Epoch [31/50], Step [300/938], D Loss: 0.3200, G Loss: 3.2306, C Loss: -0.1369\n",
      "FID: 78.6292\n",
      "Epoch [31/50], Step [400/938], D Loss: 0.5388, G Loss: 2.9057, C Loss: -0.1603\n",
      "FID: 61.2917\n",
      "Epoch [31/50], Step [500/938], D Loss: 0.6203, G Loss: 3.0430, C Loss: -0.2005\n",
      "FID: 57.4065\n",
      "Epoch [31/50], Step [600/938], D Loss: 0.5256, G Loss: 3.1541, C Loss: -0.1407\n",
      "FID: 67.0906\n",
      "Epoch [31/50], Step [700/938], D Loss: 0.4278, G Loss: 3.4253, C Loss: -0.0930\n",
      "FID: 76.1237\n",
      "Epoch [31/50], Step [800/938], D Loss: 0.4644, G Loss: 2.5093, C Loss: -0.3042\n",
      "FID: 59.7975\n",
      "Epoch [31/50], Step [900/938], D Loss: 0.5429, G Loss: 2.8527, C Loss: -0.1334\n",
      "FID: 69.5561\n",
      "Epoch [32/50], Step [100/938], D Loss: 0.5604, G Loss: 1.9037, C Loss: -0.4529\n",
      "FID: 59.2076\n",
      "Epoch [32/50], Step [200/938], D Loss: 0.6305, G Loss: 2.7027, C Loss: -0.2625\n",
      "FID: 71.0846\n",
      "Epoch [32/50], Step [300/938], D Loss: 0.5803, G Loss: 2.9603, C Loss: -0.1998\n",
      "FID: 48.8213\n",
      "Epoch [32/50], Step [400/938], D Loss: 0.6305, G Loss: 2.3949, C Loss: -0.3023\n",
      "FID: 59.8249\n",
      "Epoch [32/50], Step [500/938], D Loss: 0.6184, G Loss: 2.8266, C Loss: -0.2571\n",
      "FID: 56.8012\n",
      "Epoch [32/50], Step [600/938], D Loss: 0.7515, G Loss: 2.4202, C Loss: -0.4999\n",
      "FID: 69.4956\n",
      "Epoch [32/50], Step [700/938], D Loss: 0.7861, G Loss: 2.7379, C Loss: -0.2445\n",
      "FID: 52.8585\n",
      "Epoch [32/50], Step [800/938], D Loss: 0.4991, G Loss: 2.6646, C Loss: -0.2653\n",
      "FID: 60.5495\n",
      "Epoch [32/50], Step [900/938], D Loss: 0.6363, G Loss: 2.1816, C Loss: -0.3156\n",
      "FID: 60.5032\n",
      "Epoch [33/50], Step [100/938], D Loss: 0.7924, G Loss: 2.6968, C Loss: -0.1966\n",
      "FID: 63.5520\n",
      "Epoch [33/50], Step [200/938], D Loss: 0.7021, G Loss: 2.4952, C Loss: -0.3391\n",
      "FID: 52.7166\n",
      "Epoch [33/50], Step [300/938], D Loss: 0.3985, G Loss: 2.9390, C Loss: -0.1933\n",
      "FID: 59.3754\n",
      "Epoch [33/50], Step [400/938], D Loss: 0.6250, G Loss: 2.0068, C Loss: -0.3466\n",
      "FID: 56.8713\n",
      "Epoch [33/50], Step [500/938], D Loss: 0.5049, G Loss: 1.9183, C Loss: -0.4881\n",
      "FID: 48.0954\n",
      "Epoch [33/50], Step [600/938], D Loss: 0.6832, G Loss: 1.9154, C Loss: -0.4259\n",
      "FID: 58.2725\n",
      "Epoch [33/50], Step [700/938], D Loss: 0.9070, G Loss: 1.7740, C Loss: -0.4807\n",
      "FID: 53.0398\n",
      "Epoch [33/50], Step [800/938], D Loss: 0.7599, G Loss: 1.8417, C Loss: -0.4107\n",
      "FID: 53.6283\n",
      "Epoch [33/50], Step [900/938], D Loss: 0.6186, G Loss: 2.6401, C Loss: -0.2123\n",
      "FID: 51.1970\n",
      "Epoch [34/50], Step [100/938], D Loss: 0.7137, G Loss: 2.1531, C Loss: -0.3120\n",
      "FID: 55.2142\n",
      "Epoch [34/50], Step [200/938], D Loss: 0.6746, G Loss: 1.4381, C Loss: -0.6247\n",
      "FID: 57.7061\n",
      "Epoch [34/50], Step [300/938], D Loss: 0.7270, G Loss: 2.0484, C Loss: -0.3965\n",
      "FID: 72.9419\n",
      "Epoch [34/50], Step [400/938], D Loss: 0.7030, G Loss: 2.8898, C Loss: -0.2391\n",
      "FID: 58.8710\n",
      "Epoch [34/50], Step [500/938], D Loss: 0.9735, G Loss: 2.9972, C Loss: -0.1532\n",
      "FID: 56.4889\n",
      "Epoch [34/50], Step [600/938], D Loss: 0.7162, G Loss: 2.5734, C Loss: -0.1908\n",
      "FID: 59.9840\n",
      "Epoch [34/50], Step [700/938], D Loss: 0.7111, G Loss: 2.1372, C Loss: -0.3136\n",
      "FID: 64.6875\n",
      "Epoch [34/50], Step [800/938], D Loss: 0.5140, G Loss: 2.6077, C Loss: -0.2483\n",
      "FID: 65.0650\n",
      "Epoch [34/50], Step [900/938], D Loss: 0.6963, G Loss: 3.3512, C Loss: -0.0913\n",
      "FID: 58.5649\n",
      "Epoch [35/50], Step [100/938], D Loss: 0.6015, G Loss: 2.4632, C Loss: -0.2676\n",
      "FID: 61.5235\n",
      "Epoch [35/50], Step [200/938], D Loss: 0.9965, G Loss: 3.0815, C Loss: -0.1791\n",
      "FID: 57.6109\n",
      "Epoch [35/50], Step [300/938], D Loss: 0.8413, G Loss: 2.6433, C Loss: -0.2033\n",
      "FID: 54.0977\n",
      "Epoch [35/50], Step [400/938], D Loss: 0.7645, G Loss: 2.0397, C Loss: -0.3801\n",
      "FID: 57.4477\n",
      "Epoch [35/50], Step [500/938], D Loss: 0.6823, G Loss: 2.7689, C Loss: -0.2216\n",
      "FID: 57.8326\n",
      "Epoch [35/50], Step [600/938], D Loss: 0.4488, G Loss: 3.2392, C Loss: -0.1302\n",
      "FID: 66.4297\n",
      "Epoch [35/50], Step [700/938], D Loss: 0.9748, G Loss: 2.1707, C Loss: -0.3690\n",
      "FID: 48.2326\n",
      "Epoch [35/50], Step [800/938], D Loss: 0.6965, G Loss: 2.4537, C Loss: -0.3164\n",
      "FID: 64.3644\n",
      "Epoch [35/50], Step [900/938], D Loss: 0.6118, G Loss: 2.7753, C Loss: -0.2335\n",
      "FID: 57.2257\n",
      "Epoch [36/50], Step [100/938], D Loss: 0.7828, G Loss: 3.1983, C Loss: -0.1905\n",
      "FID: 54.3201\n",
      "Epoch [36/50], Step [200/938], D Loss: 0.5519, G Loss: 2.6457, C Loss: -0.2848\n",
      "FID: 55.1549\n",
      "Epoch [36/50], Step [300/938], D Loss: 0.9261, G Loss: 2.4472, C Loss: -0.3118\n",
      "FID: 40.0755\n",
      "Epoch [36/50], Step [400/938], D Loss: 0.6503, G Loss: 2.7320, C Loss: -0.2033\n",
      "FID: 44.2422\n",
      "Epoch [36/50], Step [500/938], D Loss: 0.8858, G Loss: 1.4353, C Loss: -0.7144\n",
      "FID: 47.9412\n",
      "Epoch [36/50], Step [600/938], D Loss: 0.8470, G Loss: 2.2368, C Loss: -0.3266\n",
      "FID: 50.8786\n",
      "Epoch [36/50], Step [700/938], D Loss: 0.7592, G Loss: 2.0571, C Loss: -0.3011\n",
      "FID: 48.0812\n",
      "Epoch [36/50], Step [800/938], D Loss: 0.6303, G Loss: 1.7335, C Loss: -0.4118\n",
      "FID: 62.5607\n",
      "Epoch [36/50], Step [900/938], D Loss: 0.8117, G Loss: 2.1331, C Loss: -0.3181\n",
      "FID: 54.8233\n",
      "Epoch [37/50], Step [100/938], D Loss: 0.6932, G Loss: 2.1858, C Loss: -0.3695\n",
      "FID: 45.1326\n",
      "Epoch [37/50], Step [200/938], D Loss: 0.5681, G Loss: 2.5363, C Loss: -0.1928\n",
      "FID: 57.3993\n",
      "Epoch [37/50], Step [300/938], D Loss: 0.6549, G Loss: 2.2285, C Loss: -0.2863\n",
      "FID: 59.0121\n",
      "Epoch [37/50], Step [400/938], D Loss: 0.6932, G Loss: 1.8065, C Loss: -0.4426\n",
      "FID: 51.8386\n",
      "Epoch [37/50], Step [500/938], D Loss: 0.7366, G Loss: 2.0993, C Loss: -0.3914\n",
      "FID: 54.1561\n",
      "Epoch [37/50], Step [600/938], D Loss: 0.7088, G Loss: 2.3433, C Loss: -0.3346\n",
      "FID: 43.5993\n",
      "Epoch [37/50], Step [700/938], D Loss: 0.8000, G Loss: 1.9724, C Loss: -0.4236\n",
      "FID: 46.5891\n",
      "Epoch [37/50], Step [800/938], D Loss: 0.9353, G Loss: 3.3623, C Loss: -0.1969\n",
      "FID: 51.5994\n",
      "Epoch [37/50], Step [900/938], D Loss: 0.6820, G Loss: 2.5837, C Loss: -0.2764\n",
      "FID: 53.7066\n",
      "Epoch [38/50], Step [100/938], D Loss: 0.8374, G Loss: 2.3707, C Loss: -0.3340\n",
      "FID: 55.7928\n",
      "Epoch [38/50], Step [200/938], D Loss: 0.8797, G Loss: 2.3917, C Loss: -0.2950\n",
      "FID: 47.4063\n",
      "Epoch [38/50], Step [300/938], D Loss: 0.7708, G Loss: 1.8749, C Loss: -0.3433\n",
      "FID: 52.5399\n",
      "Epoch [38/50], Step [400/938], D Loss: 0.5075, G Loss: 2.1310, C Loss: -0.2568\n",
      "FID: 45.1086\n",
      "Epoch [38/50], Step [500/938], D Loss: 0.6675, G Loss: 2.3113, C Loss: -0.2984\n",
      "FID: 51.2941\n",
      "Epoch [38/50], Step [600/938], D Loss: 0.8948, G Loss: 2.2606, C Loss: -0.2961\n",
      "FID: 34.8955\n",
      "Epoch [38/50], Step [700/938], D Loss: 0.6751, G Loss: 2.2391, C Loss: -0.2867\n",
      "FID: 66.8320\n",
      "Epoch [38/50], Step [800/938], D Loss: 0.5073, G Loss: 2.0951, C Loss: -0.3914\n",
      "FID: 51.3025\n",
      "Epoch [38/50], Step [900/938], D Loss: 0.9322, G Loss: 3.1448, C Loss: -0.1419\n",
      "FID: 52.4878\n",
      "Epoch [39/50], Step [100/938], D Loss: 0.9808, G Loss: 1.4675, C Loss: -0.7539\n",
      "FID: 39.0228\n",
      "Epoch [39/50], Step [200/938], D Loss: 0.6607, G Loss: 3.3603, C Loss: -0.1417\n",
      "FID: 58.6709\n",
      "Epoch [39/50], Step [300/938], D Loss: 0.7753, G Loss: 2.3137, C Loss: -0.3405\n",
      "FID: 52.3696\n",
      "Epoch [39/50], Step [400/938], D Loss: 0.6981, G Loss: 2.1405, C Loss: -0.2581\n",
      "FID: 67.4822\n",
      "Epoch [39/50], Step [500/938], D Loss: 0.8179, G Loss: 1.7631, C Loss: -0.5293\n",
      "FID: 45.5926\n",
      "Epoch [39/50], Step [600/938], D Loss: 0.8588, G Loss: 2.7738, C Loss: -0.2749\n",
      "FID: 51.5472\n",
      "Epoch [39/50], Step [700/938], D Loss: 0.6959, G Loss: 2.8673, C Loss: -0.1704\n",
      "FID: 58.3075\n",
      "Epoch [39/50], Step [800/938], D Loss: 0.9532, G Loss: 2.5238, C Loss: -0.2558\n",
      "FID: 55.4024\n",
      "Epoch [39/50], Step [900/938], D Loss: 0.5934, G Loss: 2.0845, C Loss: -0.3199\n",
      "FID: 54.4763\n",
      "Epoch [40/50], Step [100/938], D Loss: 0.7105, G Loss: 1.9451, C Loss: -0.3547\n",
      "FID: 40.4732\n",
      "Epoch [40/50], Step [200/938], D Loss: 0.6794, G Loss: 2.3409, C Loss: -0.2708\n",
      "FID: 62.3105\n",
      "Epoch [40/50], Step [300/938], D Loss: 0.5423, G Loss: 2.6060, C Loss: -0.2428\n",
      "FID: 48.0494\n",
      "Epoch [40/50], Step [400/938], D Loss: 0.7250, G Loss: 2.5749, C Loss: -0.2258\n",
      "FID: 53.1035\n",
      "Epoch [40/50], Step [500/938], D Loss: 0.6930, G Loss: 2.1906, C Loss: -0.3214\n",
      "FID: 50.1256\n",
      "Epoch [40/50], Step [600/938], D Loss: 0.7000, G Loss: 1.9369, C Loss: -0.3858\n",
      "FID: 35.0009\n",
      "Epoch [40/50], Step [700/938], D Loss: 0.8072, G Loss: 2.0509, C Loss: -0.3588\n",
      "FID: 49.7764\n",
      "Epoch [40/50], Step [800/938], D Loss: 0.7692, G Loss: 2.0274, C Loss: -0.3425\n",
      "FID: 42.3245\n",
      "Epoch [40/50], Step [900/938], D Loss: 0.6875, G Loss: 1.8676, C Loss: -0.4392\n",
      "FID: 48.4177\n",
      "Epoch [41/50], Step [100/938], D Loss: 0.6578, G Loss: 2.3721, C Loss: -0.2987\n",
      "FID: 35.2502\n",
      "Epoch [41/50], Step [200/938], D Loss: 0.7872, G Loss: 1.9022, C Loss: -0.3631\n",
      "FID: 62.6625\n",
      "Epoch [41/50], Step [300/938], D Loss: 0.5816, G Loss: 2.8479, C Loss: -0.1791\n",
      "FID: 52.0874\n",
      "Epoch [41/50], Step [400/938], D Loss: 0.5245, G Loss: 2.7411, C Loss: -0.1462\n",
      "FID: 42.5045\n",
      "Epoch [41/50], Step [500/938], D Loss: 0.5768, G Loss: 2.6605, C Loss: -0.2249\n",
      "FID: 46.9138\n",
      "Epoch [41/50], Step [600/938], D Loss: 0.7102, G Loss: 1.7297, C Loss: -0.5505\n",
      "FID: 40.5377\n",
      "Epoch [41/50], Step [700/938], D Loss: 0.7377, G Loss: 1.8270, C Loss: -0.3290\n",
      "FID: 59.0127\n",
      "Epoch [41/50], Step [800/938], D Loss: 0.6506, G Loss: 2.3285, C Loss: -0.2695\n",
      "FID: 44.8993\n",
      "Epoch [41/50], Step [900/938], D Loss: 0.8625, G Loss: 1.8157, C Loss: -0.4602\n",
      "FID: 40.2305\n",
      "Epoch [42/50], Step [100/938], D Loss: 0.6970, G Loss: 2.1083, C Loss: -0.3109\n",
      "FID: 41.4445\n",
      "Epoch [42/50], Step [200/938], D Loss: 1.0016, G Loss: 2.5764, C Loss: -0.2116\n",
      "FID: 37.1731\n",
      "Epoch [42/50], Step [300/938], D Loss: 0.7112, G Loss: 1.8650, C Loss: -0.4801\n",
      "FID: 43.7665\n",
      "Epoch [42/50], Step [400/938], D Loss: 0.6586, G Loss: 1.8197, C Loss: -0.3527\n",
      "FID: 37.1046\n",
      "Epoch [42/50], Step [500/938], D Loss: 0.8484, G Loss: 2.0753, C Loss: -0.2665\n",
      "FID: 28.6906\n",
      "Epoch [42/50], Step [600/938], D Loss: 0.5309, G Loss: 2.4787, C Loss: -0.1715\n",
      "FID: 47.4586\n",
      "Epoch [42/50], Step [700/938], D Loss: 0.8939, G Loss: 1.4374, C Loss: -0.5560\n",
      "FID: 45.1780\n",
      "Epoch [42/50], Step [800/938], D Loss: 0.8611, G Loss: 1.6003, C Loss: -0.4430\n",
      "FID: 35.2165\n",
      "Epoch [42/50], Step [900/938], D Loss: 0.7743, G Loss: 1.8360, C Loss: -0.3945\n",
      "FID: 34.9783\n",
      "Epoch [43/50], Step [100/938], D Loss: 0.8297, G Loss: 1.8852, C Loss: -0.4772\n",
      "FID: 42.5399\n",
      "Epoch [43/50], Step [200/938], D Loss: 0.5785, G Loss: 2.1352, C Loss: -0.2817\n",
      "FID: 40.8933\n",
      "Epoch [43/50], Step [300/938], D Loss: 0.7168, G Loss: 2.1271, C Loss: -0.2926\n",
      "FID: 39.0411\n",
      "Epoch [43/50], Step [400/938], D Loss: 0.8059, G Loss: 1.8242, C Loss: -0.3685\n",
      "FID: 42.9912\n",
      "Epoch [43/50], Step [500/938], D Loss: 0.8051, G Loss: 1.9914, C Loss: -0.3612\n",
      "FID: 39.8001\n",
      "Epoch [43/50], Step [600/938], D Loss: 0.6175, G Loss: 1.6506, C Loss: -0.4576\n",
      "FID: 31.7125\n",
      "Epoch [43/50], Step [700/938], D Loss: 0.9780, G Loss: 1.4605, C Loss: -0.4762\n",
      "FID: 32.6763\n",
      "Epoch [43/50], Step [800/938], D Loss: 0.9300, G Loss: 2.4490, C Loss: -0.2179\n",
      "FID: 34.4416\n",
      "Epoch [43/50], Step [900/938], D Loss: 0.8821, G Loss: 1.4340, C Loss: -0.4994\n",
      "FID: 28.7298\n",
      "Epoch [44/50], Step [100/938], D Loss: 0.6336, G Loss: 2.3375, C Loss: -0.2224\n",
      "FID: 26.3972\n",
      "Epoch [44/50], Step [200/938], D Loss: 0.9410, G Loss: 1.5065, C Loss: -0.5781\n",
      "FID: 38.1195\n",
      "Epoch [44/50], Step [300/938], D Loss: 0.9951, G Loss: 1.5282, C Loss: -0.4522\n",
      "FID: 38.7879\n",
      "Epoch [44/50], Step [400/938], D Loss: 0.7532, G Loss: 1.7007, C Loss: -0.4658\n",
      "FID: 46.0930\n",
      "Epoch [44/50], Step [500/938], D Loss: 0.9294, G Loss: 1.5004, C Loss: -0.4994\n",
      "FID: 41.7599\n",
      "Epoch [44/50], Step [600/938], D Loss: 0.8572, G Loss: 1.9654, C Loss: -0.3047\n",
      "FID: 37.3298\n",
      "Epoch [44/50], Step [700/938], D Loss: 0.8378, G Loss: 2.1675, C Loss: -0.3079\n",
      "FID: 46.2827\n",
      "Epoch [44/50], Step [800/938], D Loss: 0.8798, G Loss: 1.6201, C Loss: -0.4497\n",
      "FID: 26.6025\n",
      "Epoch [44/50], Step [900/938], D Loss: 0.8644, G Loss: 2.4325, C Loss: -0.3128\n",
      "FID: 37.6109\n",
      "Epoch [45/50], Step [100/938], D Loss: 0.5695, G Loss: 1.9060, C Loss: -0.3163\n",
      "FID: 34.8170\n",
      "Epoch [45/50], Step [200/938], D Loss: 0.8383, G Loss: 2.0617, C Loss: -0.3131\n",
      "FID: 24.0664\n",
      "Epoch [45/50], Step [300/938], D Loss: 0.8395, G Loss: 2.4684, C Loss: -0.2402\n",
      "FID: 43.9355\n",
      "Epoch [45/50], Step [400/938], D Loss: 0.7664, G Loss: 2.4853, C Loss: -0.2487\n",
      "FID: 41.9690\n",
      "Epoch [45/50], Step [500/938], D Loss: 0.8043, G Loss: 2.1161, C Loss: -0.3042\n",
      "FID: 50.1597\n",
      "Epoch [45/50], Step [600/938], D Loss: 0.6384, G Loss: 2.2188, C Loss: -0.2557\n",
      "FID: 38.9584\n",
      "Epoch [45/50], Step [700/938], D Loss: 0.9176, G Loss: 1.9893, C Loss: -0.3524\n",
      "FID: 39.8632\n",
      "Epoch [45/50], Step [800/938], D Loss: 0.9469, G Loss: 1.6709, C Loss: -0.4786\n",
      "FID: 49.6693\n",
      "Epoch [45/50], Step [900/938], D Loss: 0.6150, G Loss: 2.3286, C Loss: -0.2883\n",
      "FID: 41.5800\n",
      "Epoch [46/50], Step [100/938], D Loss: 0.8304, G Loss: 1.9656, C Loss: -0.3198\n",
      "FID: 34.0712\n",
      "Epoch [46/50], Step [200/938], D Loss: 0.6761, G Loss: 1.9819, C Loss: -0.3454\n",
      "FID: 33.6966\n",
      "Epoch [46/50], Step [300/938], D Loss: 0.9824, G Loss: 1.9641, C Loss: -0.3283\n",
      "FID: 30.6997\n",
      "Epoch [46/50], Step [400/938], D Loss: 0.9705, G Loss: 1.4049, C Loss: -0.5645\n",
      "FID: 35.1982\n",
      "Epoch [46/50], Step [500/938], D Loss: 0.8797, G Loss: 1.6705, C Loss: -0.4019\n",
      "FID: 42.8527\n",
      "Epoch [46/50], Step [600/938], D Loss: 0.6302, G Loss: 2.4508, C Loss: -0.2276\n",
      "FID: 39.0307\n",
      "Epoch [46/50], Step [700/938], D Loss: 0.6786, G Loss: 1.9769, C Loss: -0.2961\n",
      "FID: 36.7628\n",
      "Epoch [46/50], Step [800/938], D Loss: 0.8588, G Loss: 1.5431, C Loss: -0.5373\n",
      "FID: 33.8223\n",
      "Epoch [46/50], Step [900/938], D Loss: 0.8756, G Loss: 1.4541, C Loss: -0.5691\n",
      "FID: 43.0721\n",
      "Epoch [47/50], Step [100/938], D Loss: 0.9933, G Loss: 1.5671, C Loss: -0.4610\n",
      "FID: 43.8819\n",
      "Epoch [47/50], Step [200/938], D Loss: 0.9620, G Loss: 1.7276, C Loss: -0.4751\n",
      "FID: 24.8476\n",
      "Epoch [47/50], Step [300/938], D Loss: 0.6868, G Loss: 2.1838, C Loss: -0.2791\n",
      "FID: 38.0524\n",
      "Epoch [47/50], Step [400/938], D Loss: 0.8457, G Loss: 1.8645, C Loss: -0.4690\n",
      "FID: 26.2596\n",
      "Epoch [47/50], Step [500/938], D Loss: 0.8330, G Loss: 1.7907, C Loss: -0.3635\n",
      "FID: 39.9592\n",
      "Epoch [47/50], Step [600/938], D Loss: 0.8447, G Loss: 1.6180, C Loss: -0.5367\n",
      "FID: 30.1877\n",
      "Epoch [47/50], Step [700/938], D Loss: 0.8308, G Loss: 2.4808, C Loss: -0.2343\n",
      "FID: 26.1965\n",
      "Epoch [47/50], Step [800/938], D Loss: 1.2308, G Loss: 1.7330, C Loss: -0.3789\n",
      "FID: 27.4731\n",
      "Epoch [47/50], Step [900/938], D Loss: 0.8721, G Loss: 1.4342, C Loss: -0.5328\n",
      "FID: 28.2144\n",
      "Epoch [48/50], Step [100/938], D Loss: 0.8369, G Loss: 1.9147, C Loss: -0.3244\n",
      "FID: 36.7580\n",
      "Epoch [48/50], Step [200/938], D Loss: 0.6736, G Loss: 2.1121, C Loss: -0.3548\n",
      "FID: 35.2379\n",
      "Epoch [48/50], Step [300/938], D Loss: 0.7065, G Loss: 1.8377, C Loss: -0.3782\n",
      "FID: 45.7972\n",
      "Epoch [48/50], Step [400/938], D Loss: 0.8611, G Loss: 2.0986, C Loss: -0.3308\n",
      "FID: 27.8412\n",
      "Epoch [48/50], Step [500/938], D Loss: 0.7107, G Loss: 1.6855, C Loss: -0.3660\n",
      "FID: 36.5142\n",
      "Epoch [48/50], Step [600/938], D Loss: 0.8710, G Loss: 1.4294, C Loss: -0.6249\n",
      "FID: 41.9587\n",
      "Epoch [48/50], Step [700/938], D Loss: 0.8570, G Loss: 2.1552, C Loss: -0.3300\n",
      "FID: 33.4822\n",
      "Epoch [48/50], Step [800/938], D Loss: 1.1067, G Loss: 1.9457, C Loss: -0.3635\n",
      "FID: 27.5445\n",
      "Epoch [48/50], Step [900/938], D Loss: 1.2513, G Loss: 1.5870, C Loss: -0.5492\n",
      "FID: 31.2718\n",
      "Epoch [49/50], Step [100/938], D Loss: 0.8577, G Loss: 1.4219, C Loss: -0.5946\n",
      "FID: 31.8676\n",
      "Epoch [49/50], Step [200/938], D Loss: 0.9569, G Loss: 1.5814, C Loss: -0.5172\n",
      "FID: 41.0520\n",
      "Epoch [49/50], Step [300/938], D Loss: 1.2500, G Loss: 1.2511, C Loss: -0.7120\n",
      "FID: 30.4320\n",
      "Epoch [49/50], Step [400/938], D Loss: 1.0132, G Loss: 1.6096, C Loss: -0.4891\n",
      "FID: 24.5853\n",
      "Epoch [49/50], Step [500/938], D Loss: 0.9257, G Loss: 1.9685, C Loss: -0.2873\n",
      "FID: 31.4198\n",
      "Epoch [49/50], Step [600/938], D Loss: 0.9810, G Loss: 1.4111, C Loss: -0.5088\n",
      "FID: 30.3263\n",
      "Epoch [49/50], Step [700/938], D Loss: 0.9851, G Loss: 1.4851, C Loss: -0.5100\n",
      "FID: 47.5443\n",
      "Epoch [49/50], Step [800/938], D Loss: 1.0571, G Loss: 1.8101, C Loss: -0.4876\n",
      "FID: 24.9752\n",
      "Epoch [49/50], Step [900/938], D Loss: 1.0718, G Loss: 1.7329, C Loss: -0.4006\n",
      "FID: 22.4372\n",
      "Epoch [50/50], Step [100/938], D Loss: 1.0474, G Loss: 1.3592, C Loss: -0.5674\n",
      "FID: 29.1812\n",
      "Epoch [50/50], Step [200/938], D Loss: 0.8806, G Loss: 1.9483, C Loss: -0.3664\n",
      "FID: 35.0019\n",
      "Epoch [50/50], Step [300/938], D Loss: 0.9327, G Loss: 1.5418, C Loss: -0.4530\n",
      "FID: 21.0899\n",
      "Epoch [50/50], Step [400/938], D Loss: 1.0938, G Loss: 1.4701, C Loss: -0.5507\n",
      "FID: 26.7339\n",
      "Epoch [50/50], Step [500/938], D Loss: 0.9596, G Loss: 1.3498, C Loss: -0.5357\n",
      "FID: 24.9168\n",
      "Epoch [50/50], Step [600/938], D Loss: 0.8802, G Loss: 2.3491, C Loss: -0.2113\n",
      "FID: 36.6181\n",
      "Epoch [50/50], Step [700/938], D Loss: 0.7099, G Loss: 1.9249, C Loss: -0.3232\n",
      "FID: 25.3965\n",
      "Epoch [50/50], Step [800/938], D Loss: 0.8513, G Loss: 1.9078, C Loss: -0.3821\n",
      "FID: 25.8579\n",
      "Epoch [50/50], Step [900/938], D Loss: 0.8928, G Loss: 1.2763, C Loss: -0.6030\n",
      "FID: 28.4185\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correlation device is a simple neural network that takes a signal as input and outputs a probability distribution\n",
    "class CorrelationDevice(nn.Module):\n",
    "    def __init__(self, signal_dim):\n",
    "        super(CorrelationDevice, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(signal_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, signal_dim),\n",
    "            nn.Softmax(dim=-1)  # Assuming a categorical signal\n",
    "        )\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        return self.main(signal)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, signal_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim + signal_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, output_dim),\n",
    "            nn.Tanh()  # Assuming the output is a normalized image\n",
    "        )\n",
    "        \n",
    "    def forward(self, noise, signal):\n",
    "        combined_input = torch.cat((noise, signal), 1)\n",
    "        return self.main(combined_input)\n",
    "\n",
    "# Define the Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, signal_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim + signal_dim, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()  # Output probability of being real\n",
    "        )\n",
    "        \n",
    "    def forward(self, sample, signal):\n",
    "        combined_input = torch.cat((sample, signal), 1)\n",
    "        return self.main(combined_input)\n",
    "\n",
    "# Parameters\n",
    "batch_size = 64\n",
    "signal_dim = 10\n",
    "noise_dim = 100  # size of the g's input noise vector\n",
    "image_dim = 28*28  # flatten MNIST\n",
    "learning_rate = 0.0002\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize MNIST \n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "C = CorrelationDevice(signal_dim=signal_dim)\n",
    "G = Generator(input_dim=noise_dim, signal_dim=signal_dim, output_dim=image_dim)\n",
    "D = Discriminator(input_dim=image_dim, signal_dim=signal_dim)\n",
    "\n",
    "optimizer_C = optim.Adam(C.parameters(), lr=learning_rate)\n",
    "optimizer_G = optim.Adam(G.parameters(), lr=learning_rate)\n",
    "optimizer_D = optim.Adam(D.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 50\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def difficulty_ramp(difficulty, max_difficulty, growth_rate):\n",
    "    # A logistic growth function to increase difficulty\n",
    "    return max_difficulty / (1 + np.exp(-growth_rate * (difficulty - max_difficulty/2)))\n",
    "\n",
    "C.to(device)\n",
    "G.to(device)\n",
    "D.to(device)\n",
    "\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real_images, _) in enumerate(dataloader):\n",
    "        batch_size = real_images.size(0)\n",
    "        real_images = real_images.view(batch_size, -1).to(device) # flatten\n",
    "\n",
    "        # create labels for real and fake\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # generate random noise + signals\n",
    "        noise = torch.randn(batch_size, noise_dim, device=device)\n",
    "        signals = torch.randn(batch_size, signal_dim, device=device)\n",
    "        correlated_signals = C(signals)\n",
    "\n",
    "        # use G to get fake images\n",
    "        fake_images = G(noise, correlated_signals.detach())\n",
    "\n",
    "        # D train\n",
    "        D_real = D(real_images, correlated_signals.detach())\n",
    "        D_fake = D(fake_images, correlated_signals.detach())\n",
    "        D_loss_real = adversarial_loss(D_real, real_labels)\n",
    "        D_loss_fake = adversarial_loss(D_fake, fake_labels)\n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        D_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # G train\n",
    "        correlated_signals = C(signals)\n",
    "        fake_images = G(noise, correlated_signals)\n",
    "        D_fake = D(fake_images, correlated_signals)\n",
    "        G_loss = adversarial_loss(D_fake, real_labels)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        G_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # C train\n",
    "        # Using assumption that improving G's performance is beneficial for C\n",
    "        # apply difficulty ramp to gradually increase difficulty\n",
    "        difficulty = difficulty_ramp(epoch * len(dataloader) + i, max_difficulty=1.0, growth_rate=0.05)\n",
    "        signals = torch.randn(batch_size, signal_dim, device=device) * difficulty\n",
    "        correlated_signals = C(signals)\n",
    "        fake_images = G(noise, correlated_signals)\n",
    "        D_fake = D(fake_images, correlated_signals)\n",
    "        C_loss = -adversarial_loss(D_fake, fake_labels) \n",
    "\n",
    "        optimizer_C.zero_grad()\n",
    "        C_loss.backward()\n",
    "        optimizer_C.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], '\n",
    "                  f'D Loss: {D_loss.item():.4f}, G Loss: {G_loss.item():.4f}, C Loss: {C_loss.item():.4f}')\n",
    "        \n",
    "        # FID calculation for generated MNIST images\n",
    "        if (i+1) % 100 == 0:\n",
    "            mu1, sigma1 = torch.mean(real_images, dim=0), torch.std(real_images, dim=0)\n",
    "            mu2, sigma2 = torch.mean(fake_images, dim=0), torch.std(fake_images, dim=0)\n",
    "            FID = ((mu1 - mu2)**2 + (sigma1 - sigma2)**2).sum().item()\n",
    "            print(f'FID: {FID:.4f}')\n",
    "        \n",
    "\n",
    "def show_generated_images(generator, correlation_device, noise_dim, signal_dim, num_images=10):\n",
    "    noise = torch.randn(num_images, noise_dim, device=device)\n",
    "    signals = torch.randn(num_images, signal_dim, device=device)\n",
    "    with torch.no_grad():\n",
    "        correlated_signals = correlation_device(signals)\n",
    "        generated_images = generator(noise, correlated_signals).cpu().view(num_images, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, image in enumerate(generated_images):\n",
    "        plt.subplot(2, num_images//2, i+1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_generated_images(G, C, noise_dim, signal_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs-8395",
   "language": "python",
   "name": "cs-8395"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
